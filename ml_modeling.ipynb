{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>...</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>TmNetRtg</th>\n",
       "      <th>Next Rtg</th>\n",
       "      <th>Next WS</th>\n",
       "      <th>Veteran Value</th>\n",
       "      <th>VV Class</th>\n",
       "      <th>Starters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Vinny Del</td>\n",
       "      <td>SG</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.529</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.868</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2903.225806</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Avery Johnson</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14558.823529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1997</td>\n",
       "      <td>Charles Barkley</td>\n",
       "      <td>PF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.694</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1276.595745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1997</td>\n",
       "      <td>Clyde Drexler</td>\n",
       "      <td>SG</td>\n",
       "      <td>34.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.548</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-2407.407407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1997</td>\n",
       "      <td>Mario Elie</td>\n",
       "      <td>SF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.896</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-8595.505618</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year           Player Pos   Age   Tm     G      MP   PER  \\\n",
       "0           1  1997        Vinny Del  SG  30.0  SAS  72.0  2243.0  14.4   \n",
       "1           3  1997    Avery Johnson  PG  31.0  SAS  76.0  2472.0  15.0   \n",
       "2           7  1997  Charles Barkley  PF  33.0  HOU  53.0  2009.0  23.0   \n",
       "3           8  1997    Clyde Drexler  SG  34.0  HOU  62.0  2271.0  19.9   \n",
       "4           9  1997       Mario Elie  SF  33.0  HOU  78.0  2687.0  14.3   \n",
       "\n",
       "     TS%  ...  DBPM    3P%    2P%    FT%  TmNetRtg  Next Rtg  Next WS  \\\n",
       "0  0.529  ...  -2.3  0.314  0.501  0.868      -8.8       4.4      3.7   \n",
       "1  0.517  ...  -3.0  0.231  0.487  0.690      -8.8       4.4      6.7   \n",
       "2  0.581  ...   2.8  0.283  0.569  0.694       4.7      -0.9      8.6   \n",
       "3  0.548  ...   1.7  0.355  0.493  0.750       4.7      -0.9      6.8   \n",
       "4  0.662  ...   0.1  0.420  0.572  0.896       4.7      -0.9      3.8   \n",
       "\n",
       "   Veteran Value  VV Class  Starters  \n",
       "0    2903.225806         0         1  \n",
       "1   14558.823529         0         1  \n",
       "2   -1276.595745         1         1  \n",
       "3   -2407.407407         1         1  \n",
       "4   -8595.505618         1         1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP', 'PER',\n",
       "       'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'AST%', 'STL%', 'BLK%', 'TOV%',\n",
       "       'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', '3P%', '2P%',\n",
       "       'FT%', 'TmNetRtg', 'Next Rtg', 'Next WS', 'Veteran Value', 'VV Class',\n",
       "       'Starters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Veteran Value'].plot.hist(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-63806.593259548616 63843.64009831145\n"
     ]
    }
   ],
   "source": [
    "# calculate summary statistics\n",
    "data = df['Veteran Value']\n",
    "data_mean, data_std = np.mean(data), np.std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "print(lower, upper)\n",
    "lower, upper = -10000, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [x[0] for x in enumerate(data) if x[1] < lower or x[1] > upper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=outliers,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = [x[0] for x in enumerate(df['Veteran Value']) if x[1] < lower or x[1] > upper]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Veteran Value'].plot.hist(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Veteran Value']\n",
    "\n",
    "def getClass(vv):\n",
    "    d25, d50, d75 = df['Veteran Value'].describe()['25%'], df['Veteran Value'].describe()['50%'], df['Veteran Value'].describe()['75%']\n",
    "    if vv < -5000:\n",
    "        return 0\n",
    "    elif -5000 <= vv < -1000:\n",
    "        return 1\n",
    "    elif -1000 <= vv < 0:\n",
    "        return 2\n",
    "    elif 0 <= vv < 1000:\n",
    "        return 3\n",
    "    elif 1000 <= vv < 3000:\n",
    "        return 4\n",
    "    elif 3000 <= vv:\n",
    "        return 5\n",
    "    \n",
    "df['VV Class'] = [getClass(vv) for vv in df['Veteran Value']]\n",
    "target_class = df['VV Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     641.000000\n",
       "mean     -255.310744\n",
       "std      2189.684947\n",
       "min     -9730.639731\n",
       "25%         0.161765\n",
       "50%         4.359133\n",
       "75%        68.129032\n",
       "max      8566.433566\n",
       "Name: Veteran Value, dtype: float64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Veteran Value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','Age','Year','Player','Pos','Tm','Next WS','WS','Next Rtg','TmNetRtg','Veteran Value', 'VV Class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'AST%', 'STL%',\n",
       "       'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS/48', 'OBPM', 'DBPM', '3P%',\n",
       "       '2P%', 'FT%', 'Starters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try scaling values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(scaled_data, target_class.values, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6832298136645962"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "clf = LogisticRegression(tol=1e-4, max_iter=1000, random_state=0).fit(xtrain, ytrain)\n",
    "clf.predict(xtest)\n",
    "clf.predict_proba(xtest)\n",
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6477007624870357"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,clf.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "n_neighbors=15\n",
    "neigh = KNeighborsClassifier(n_neighbors)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2342857142857143"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.predict_proba(xtest)\n",
    "neigh.score(xctest,yctest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5831359587536598"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,neigh.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6832298136645962"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=250, max_depth=50, min_samples_leaf=10, min_samples_split = 10, max_features=10)\n",
    "rf.fit(xtrain, ytrain)\n",
    "rf.predict_proba(xtest)\n",
    "rf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5708658292995925"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,rf.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894409937888198"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(min_samples_split=2**6, max_depth=10), \n",
    "                         n_estimators=225, learning_rate=0.5)\n",
    "abc.fit(xtrain, ytrain)\n",
    "abc.predict_proba(xtest)\n",
    "abc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6211652474645523"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,abc.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.97844663\n",
      "Iteration 2, loss = 1.69998579\n",
      "Iteration 3, loss = 1.48990651\n",
      "Iteration 4, loss = 1.30260975\n",
      "Iteration 5, loss = 1.20831273\n",
      "Iteration 6, loss = 1.22209619\n",
      "Iteration 7, loss = 1.26511413\n",
      "Iteration 8, loss = 1.26496531\n",
      "Iteration 9, loss = 1.22570686\n",
      "Iteration 10, loss = 1.19253641\n",
      "Iteration 11, loss = 1.17470989\n",
      "Iteration 12, loss = 1.17361886\n",
      "Iteration 13, loss = 1.17540912\n",
      "Iteration 14, loss = 1.16899415\n",
      "Iteration 15, loss = 1.15781411\n",
      "Iteration 16, loss = 1.14840221\n",
      "Iteration 17, loss = 1.14346877\n",
      "Iteration 18, loss = 1.14496726\n",
      "Iteration 19, loss = 1.14433392\n",
      "Iteration 20, loss = 1.14122480\n",
      "Iteration 21, loss = 1.13554836\n",
      "Iteration 22, loss = 1.13207471\n",
      "Iteration 23, loss = 1.13166579\n",
      "Iteration 24, loss = 1.13027092\n",
      "Iteration 25, loss = 1.12722609\n",
      "Iteration 26, loss = 1.12381481\n",
      "Iteration 27, loss = 1.12137932\n",
      "Iteration 28, loss = 1.12012090\n",
      "Iteration 29, loss = 1.11826549\n",
      "Iteration 30, loss = 1.11613748\n",
      "Iteration 31, loss = 1.11455763\n",
      "Iteration 32, loss = 1.11285015\n",
      "Iteration 33, loss = 1.11071648\n",
      "Iteration 34, loss = 1.10870334\n",
      "Iteration 35, loss = 1.10761311\n",
      "Iteration 36, loss = 1.10561356\n",
      "Iteration 37, loss = 1.10333288\n",
      "Iteration 38, loss = 1.10296247\n",
      "Iteration 39, loss = 1.10062501\n",
      "Iteration 40, loss = 1.09974841\n",
      "Iteration 41, loss = 1.09716050\n",
      "Iteration 42, loss = 1.09553597\n",
      "Iteration 43, loss = 1.09443772\n",
      "Iteration 44, loss = 1.09218319\n",
      "Iteration 45, loss = 1.09051722\n",
      "Iteration 46, loss = 1.08890790\n",
      "Iteration 47, loss = 1.08739203\n",
      "Iteration 48, loss = 1.08638657\n",
      "Iteration 49, loss = 1.08474234\n",
      "Iteration 50, loss = 1.08236451\n",
      "Iteration 51, loss = 1.08111191\n",
      "Iteration 52, loss = 1.07895532\n",
      "Iteration 53, loss = 1.07764069\n",
      "Iteration 54, loss = 1.07619223\n",
      "Iteration 55, loss = 1.07455958\n",
      "Iteration 56, loss = 1.07296736\n",
      "Iteration 57, loss = 1.07123159\n",
      "Iteration 58, loss = 1.06897629\n",
      "Iteration 59, loss = 1.06749113\n",
      "Iteration 60, loss = 1.06562654\n",
      "Iteration 61, loss = 1.06417894\n",
      "Iteration 62, loss = 1.06271408\n",
      "Iteration 63, loss = 1.06118061\n",
      "Iteration 64, loss = 1.05757912\n",
      "Iteration 65, loss = 1.05732869\n",
      "Iteration 66, loss = 1.05554843\n",
      "Iteration 67, loss = 1.05300305\n",
      "Iteration 68, loss = 1.05129032\n",
      "Iteration 69, loss = 1.04891417\n",
      "Iteration 70, loss = 1.04717488\n",
      "Iteration 71, loss = 1.04523863\n",
      "Iteration 72, loss = 1.04339053\n",
      "Iteration 73, loss = 1.04196069\n",
      "Iteration 74, loss = 1.03992902\n",
      "Iteration 75, loss = 1.03873600\n",
      "Iteration 76, loss = 1.03681576\n",
      "Iteration 77, loss = 1.03352744\n",
      "Iteration 78, loss = 1.03217546\n",
      "Iteration 79, loss = 1.03040657\n",
      "Iteration 80, loss = 1.02736540\n",
      "Iteration 81, loss = 1.02673240\n",
      "Iteration 82, loss = 1.02707149\n",
      "Iteration 83, loss = 1.02250540\n",
      "Iteration 84, loss = 1.02030912\n",
      "Iteration 85, loss = 1.01850098\n",
      "Iteration 86, loss = 1.01648852\n",
      "Iteration 87, loss = 1.01504774\n",
      "Iteration 88, loss = 1.01259563\n",
      "Iteration 89, loss = 1.01047159\n",
      "Iteration 90, loss = 1.00882488\n",
      "Iteration 91, loss = 1.00702987\n",
      "Iteration 92, loss = 1.00494993\n",
      "Iteration 93, loss = 1.00249144\n",
      "Iteration 94, loss = 1.00119100\n",
      "Iteration 95, loss = 0.99772018\n",
      "Iteration 96, loss = 0.99610064\n",
      "Iteration 97, loss = 0.99443178\n",
      "Iteration 98, loss = 0.99602399\n",
      "Iteration 99, loss = 0.98915569\n",
      "Iteration 100, loss = 0.98979629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6832298136645962"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(1000,100,10),activation='relu',learning_rate_init=0.001,batch_size=256, verbose=True,max_iter=100)\n",
    "mlpc.fit(xtrain, ytrain)\n",
    "mlpc.predict_proba(xtest)\n",
    "mlpc.score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285038766896752"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,mlpc.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ...................... (1 of 4) Processing RFC, total=   0.9s\n",
      "[Voting] ...................... (2 of 4) Processing LRC, total=   0.0s\n",
      "[Voting] ...................... (3 of 4) Processing ABC, total=   1.3s\n",
      "Iteration 1, loss = 2.05586126\n",
      "Iteration 2, loss = 1.81809291\n",
      "Iteration 3, loss = 1.64218328\n",
      "Iteration 4, loss = 1.43656200\n",
      "Iteration 5, loss = 1.28042558\n",
      "Iteration 6, loss = 1.26832691\n",
      "Iteration 7, loss = 1.30948401\n",
      "Iteration 8, loss = 1.30132534\n",
      "Iteration 9, loss = 1.25633385\n",
      "Iteration 10, loss = 1.22781226\n",
      "Iteration 11, loss = 1.22793307\n",
      "Iteration 12, loss = 1.22672505\n",
      "Iteration 13, loss = 1.22227713\n",
      "Iteration 14, loss = 1.21337990\n",
      "Iteration 15, loss = 1.20458072\n",
      "Iteration 16, loss = 1.20030642\n",
      "Iteration 17, loss = 1.19767415\n",
      "Iteration 18, loss = 1.19611518\n",
      "Iteration 19, loss = 1.19264351\n",
      "Iteration 20, loss = 1.18777023\n",
      "Iteration 21, loss = 1.18265650\n",
      "Iteration 22, loss = 1.17898209\n",
      "Iteration 23, loss = 1.17618264\n",
      "Iteration 24, loss = 1.17307489\n",
      "Iteration 25, loss = 1.16966126\n",
      "Iteration 26, loss = 1.16626271\n",
      "Iteration 27, loss = 1.16317458\n",
      "Iteration 28, loss = 1.15974797\n",
      "Iteration 29, loss = 1.15648856\n",
      "Iteration 30, loss = 1.15365511\n",
      "Iteration 31, loss = 1.15058925\n",
      "Iteration 32, loss = 1.14787509\n",
      "Iteration 33, loss = 1.14502307\n",
      "Iteration 34, loss = 1.14222530\n",
      "Iteration 35, loss = 1.13943529\n",
      "Iteration 36, loss = 1.13680889\n",
      "Iteration 37, loss = 1.13391962\n",
      "Iteration 38, loss = 1.13218544\n",
      "Iteration 39, loss = 1.12878769\n",
      "Iteration 40, loss = 1.12605664\n",
      "Iteration 41, loss = 1.12353437\n",
      "Iteration 42, loss = 1.12187998\n",
      "Iteration 43, loss = 1.11878817\n",
      "Iteration 44, loss = 1.11589225\n",
      "Iteration 45, loss = 1.11345348\n",
      "Iteration 46, loss = 1.11095715\n",
      "Iteration 47, loss = 1.10849651\n",
      "Iteration 48, loss = 1.10637067\n",
      "Iteration 49, loss = 1.10351496\n",
      "Iteration 50, loss = 1.10109311\n",
      "Iteration 51, loss = 1.09879086\n",
      "Iteration 52, loss = 1.09634855\n",
      "Iteration 53, loss = 1.09482333\n",
      "Iteration 54, loss = 1.09171649\n",
      "Iteration 55, loss = 1.09122591\n",
      "Iteration 56, loss = 1.08748873\n",
      "Iteration 57, loss = 1.08591166\n",
      "Iteration 58, loss = 1.08311556\n",
      "Iteration 59, loss = 1.08172240\n",
      "Iteration 60, loss = 1.07913885\n",
      "Iteration 61, loss = 1.07654585\n",
      "Iteration 62, loss = 1.07452941\n",
      "Iteration 63, loss = 1.07249367\n",
      "Iteration 64, loss = 1.06999793\n",
      "Iteration 65, loss = 1.06935155\n",
      "Iteration 66, loss = 1.06658875\n",
      "Iteration 67, loss = 1.06428973\n",
      "Iteration 68, loss = 1.06155246\n",
      "Iteration 69, loss = 1.05947521\n",
      "Iteration 70, loss = 1.05741820\n",
      "Iteration 71, loss = 1.05582674\n",
      "Iteration 72, loss = 1.05356846\n",
      "Iteration 73, loss = 1.05120873\n",
      "Iteration 74, loss = 1.04926047\n",
      "Iteration 75, loss = 1.04772518\n",
      "Iteration 76, loss = 1.04653788\n",
      "Iteration 77, loss = 1.04331006\n",
      "Iteration 78, loss = 1.04268481\n",
      "Iteration 79, loss = 1.03935338\n",
      "Iteration 80, loss = 1.03700378\n",
      "Iteration 81, loss = 1.03545652\n",
      "Iteration 82, loss = 1.03309855\n",
      "Iteration 83, loss = 1.03125305\n",
      "Iteration 84, loss = 1.02898952\n",
      "Iteration 85, loss = 1.02625002\n",
      "Iteration 86, loss = 1.02484979\n",
      "Iteration 87, loss = 1.02243557\n",
      "Iteration 88, loss = 1.01992163\n",
      "Iteration 89, loss = 1.01872929\n",
      "Iteration 90, loss = 1.01568663\n",
      "Iteration 91, loss = 1.01329418\n",
      "Iteration 92, loss = 1.01184990\n",
      "Iteration 93, loss = 1.00981014\n",
      "Iteration 94, loss = 1.00768754\n",
      "Iteration 95, loss = 1.00417029\n",
      "Iteration 96, loss = 1.00333172\n",
      "Iteration 97, loss = 0.99997022\n",
      "Iteration 98, loss = 0.99795512\n",
      "Iteration 99, loss = 0.99623419\n",
      "Iteration 100, loss = 0.99325871\n",
      "[Voting] ...................... (4 of 4) Processing MLP, total=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6832298136645962"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimator = [] \n",
    "estimator.append(('RFC',rf))\n",
    "estimator.append(('LRC',clf))\n",
    "estimator.append(('ABC',abc))\n",
    "estimator.append(('MLP',mlpc))\n",
    "\n",
    "\n",
    "vot_soft = VotingClassifier(estimators = estimator, voting='soft', verbose=True) \n",
    "vot_soft.fit(xtrain, ytrain)\n",
    "vot_soft.predict_proba(xtest)\n",
    "vot_soft.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6542899041315925"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(ytest,vot_soft.predict_proba(xtest),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
